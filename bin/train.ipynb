{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4e686c-964a-4d2f-9fd9-3b7243638654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/Proj/ml_combiner/TSEBRA/bin')\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from genome_anno import Anno\n",
    "from overlap_graph import Graph\n",
    "from evidence import Evidence\n",
    "from gnn import GNN, get_inputs\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "import time\n",
    "#physical_devices = tf.config.list_physical_devices('GPU') \n",
    "#for device in physical_devices:\n",
    "    #tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aaa51eb-fee4-4f2d-a0e7-372c02462b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"input_train[0][0]['input_nodes'][0][2].shape\\na=input_train[0]\\n#a[0]['input_nodes'][0] = np.append(a[0]['input_nodes'], input_train[1][0]['input_nodes'])\\n\\nnp.concatenate((a[0]['input_nodes'][0], input_train[1][0]['input_nodes'][0])).shape\\nprint(a[0]['incidence_matrix_sender'][0])\\nprint(input_train[31][0]['incidence_matrix_sender'][0])\\nshape1=a[0]['incidence_matrix_sender'][0].shape\\nshape2=input_train[31][0]['incidence_matrix_sender'][0].shape\\nnp.append(a[0]['incidence_matrix_sender'][0], np.zeros((shape2[0],shape1[1]), bool), axis=0)\\nnp.append(np.zeros((shape1[0],shape2[1]), bool), input_train[31][0]['incidence_matrix_sender'][0], axis=0)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"input_train[0][0]['input_nodes'][0][2].shape\n",
    "a=input_train[0]\n",
    "#a[0]['input_nodes'][0] = np.append(a[0]['input_nodes'], input_train[1][0]['input_nodes'])\n",
    "\n",
    "np.concatenate((a[0]['input_nodes'][0], input_train[1][0]['input_nodes'][0])).shape\n",
    "print(a[0]['incidence_matrix_sender'][0])\n",
    "print(input_train[31][0]['incidence_matrix_sender'][0])\n",
    "shape1=a[0]['incidence_matrix_sender'][0].shape\n",
    "shape2=input_train[31][0]['incidence_matrix_sender'][0].shape\n",
    "np.append(a[0]['incidence_matrix_sender'][0], np.zeros((shape2[0],shape1[1]), bool), axis=0)\n",
    "np.append(np.zeros((shape1[0],shape2[1]), bool), input_train[31][0]['incidence_matrix_sender'][0], axis=0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78266bd-579e-4ed9-93bf-0c5588bba1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weight():\n",
    "    global weight_class_one\n",
    "    a=0\n",
    "    b=0\n",
    "    for i in input_train:    \n",
    "        a+=1\n",
    "        for k in list(i[1].values())[0]:        \n",
    "            a += k.shape[0]\n",
    "            b += np.sum(k[:,0])\n",
    "    weight_class_one = (a-b)/b\n",
    "    print(a, b, weight_class_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b249c9c-2c40-4d72-92a1-ad292949124f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef prep_inputs():\\n    global input_train\\n    i_components = deepcopy(input_components)\\n    np.random.shuffle(i_components)\\n    input_train = [i_components[0]]    \\n    for comp in i_components[1:]:\\n        #print(comp[0]['input_edges'][0].shape, comp[0]['input_edges'][0].size)\\n        #print(len(input_train), len(input_train[-1][0]['input_nodes'][0]), len(comp[0]['input_nodes'][0]))\\n        if len(input_train[-1][0]['input_nodes'][0]) < batch_size:            \\n            for type in ['input_nodes', 'input_edges']:\\n                if comp[0][type][0].size > 0:\\n                    #print(input_train[-1][0][type][0].shape, comp[0][type][0].shape)\\n                    #print(comp[0][type][0].shape)\\n                    input_train[-1][0][type] = np.expand_dims(np.concatenate((input_train[-1][0][type][0], comp[0][type][0])),0)\\n                    #print(comp[0][type][0].shape)\\n            \\n            \\n            for type in ['incidence_matrix_sender', 'incidence_matrix_receiver']:\\n                shape1 = input_train[-1][0][type][0].shape\\n                if comp[0]['input_edges'][0].size>0:                    \\n                    shape2 = comp[0][type][0].shape\\n                    input_train[-1][0][type] = tf.expand_dims(                    \\n                        np.append( np.append(input_train[-1][0][type][0], np.zeros((shape2[0], shape1[1])), axis=0),\\n                              np.append(comp[0][type][0], np.zeros((shape1[0], shape2[1])), axis=0),\\n                            axis=1),0)\\n                else:\\n                    input_train[-1][0][type] = tf.expand_dims(                    \\n                        np.append(input_train[-1][0][type][0], \\n                                  np.zeros((comp[0]['input_nodes'][0].shape[0], shape1[1])), axis=0),0)\\n            type = 'target_label'\\n            shape1 = input_train[-1][1][type][0].shape\\n            shape2 = comp[1][type][0].shape\\n                                \\n            t = np.append( np.append(input_train[-1][1][type][0], np.zeros((shape2[0], shape1[1])), axis=0),\\n                      np.append(comp[1][type][0][:,1:], np.zeros((shape1[0], shape2[1]-1)), axis=0),\\n                    axis=1)\\n            t[shape1[0]:,0] = comp[1][type][0][:,0]\\n            input_train[-1][1][type] = tf.expand_dims(t,0)\\n        else:\\n            input_train.append(comp)\\ndef prep_inputs3():\\n    global input_train\\n    \\n    np.random.shuffle(input_components)    \\n    input_train = [[{'input_nodes' : [], 'input_edges' : [], \\n                     'incidence_matrix_sender' : [], 'incidence_matrix_receiver': []}, {'target_label' : []}]]\\n    for k, comp in enumerate(input_components):\\n        for t in input_train[-1][0].keys():\\n            input_train[-1][0][t].append(np.array(comp[0][t]))\\n        input_train[-1][1]['target_label'].append(comp[1]['target_label'])\\n        if (k+1)%batch_size == 0:\\n            for t in input_train[-1][0].keys():\\n                #print(input_train[-1][0][t])\\n                input_train[-1][0][t] = tf.ragged.constant(input_train[-1][0][t])\\n            input_train[-1][1]['target_label'] = tf.ragged.constant(input_train[-1][1]['target_label'])\\n            input_train.append([{'input_nodes' : [], 'input_edges' : [], \\n                     'incidence_matrix_sender' : [], 'incidence_matrix_receiver': []}, {'target_label' : []}])\\n        \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def prep_inputs():\n",
    "    global input_train\n",
    "    i_components = deepcopy(input_components)\n",
    "    np.random.shuffle(i_components)\n",
    "    input_train = [i_components[0]]    \n",
    "    for comp in i_components[1:]:\n",
    "        #print(comp[0]['input_edges'][0].shape, comp[0]['input_edges'][0].size)\n",
    "        #print(len(input_train), len(input_train[-1][0]['input_nodes'][0]), len(comp[0]['input_nodes'][0]))\n",
    "        if len(input_train[-1][0]['input_nodes'][0]) < batch_size:            \n",
    "            for type in ['input_nodes', 'input_edges']:\n",
    "                if comp[0][type][0].size > 0:\n",
    "                    #print(input_train[-1][0][type][0].shape, comp[0][type][0].shape)\n",
    "                    #print(comp[0][type][0].shape)\n",
    "                    input_train[-1][0][type] = np.expand_dims(np.concatenate((input_train[-1][0][type][0], comp[0][type][0])),0)\n",
    "                    #print(comp[0][type][0].shape)\n",
    "            \n",
    "            \n",
    "            for type in ['incidence_matrix_sender', 'incidence_matrix_receiver']:\n",
    "                shape1 = input_train[-1][0][type][0].shape\n",
    "                if comp[0]['input_edges'][0].size>0:                    \n",
    "                    shape2 = comp[0][type][0].shape\n",
    "                    input_train[-1][0][type] = tf.expand_dims(                    \n",
    "                        np.append( np.append(input_train[-1][0][type][0], np.zeros((shape2[0], shape1[1])), axis=0),\n",
    "                              np.append(comp[0][type][0], np.zeros((shape1[0], shape2[1])), axis=0),\n",
    "                            axis=1),0)\n",
    "                else:\n",
    "                    input_train[-1][0][type] = tf.expand_dims(                    \n",
    "                        np.append(input_train[-1][0][type][0], \n",
    "                                  np.zeros((comp[0]['input_nodes'][0].shape[0], shape1[1])), axis=0),0)\n",
    "            type = 'target_label'\n",
    "            shape1 = input_train[-1][1][type][0].shape\n",
    "            shape2 = comp[1][type][0].shape\n",
    "                                \n",
    "            t = np.append( np.append(input_train[-1][1][type][0], np.zeros((shape2[0], shape1[1])), axis=0),\n",
    "                      np.append(comp[1][type][0][:,1:], np.zeros((shape1[0], shape2[1]-1)), axis=0),\n",
    "                    axis=1)\n",
    "            t[shape1[0]:,0] = comp[1][type][0][:,0]\n",
    "            input_train[-1][1][type] = tf.expand_dims(t,0)\n",
    "        else:\n",
    "            input_train.append(comp)\n",
    "def prep_inputs3():\n",
    "    global input_train\n",
    "    \n",
    "    np.random.shuffle(input_components)    \n",
    "    input_train = [[{'input_nodes' : [], 'input_edges' : [], \n",
    "                     'incidence_matrix_sender' : [], 'incidence_matrix_receiver': []}, {'target_label' : []}]]\n",
    "    for k, comp in enumerate(input_components):\n",
    "        for t in input_train[-1][0].keys():\n",
    "            input_train[-1][0][t].append(np.array(comp[0][t]))\n",
    "        input_train[-1][1]['target_label'].append(comp[1]['target_label'])\n",
    "        if (k+1)%batch_size == 0:\n",
    "            for t in input_train[-1][0].keys():\n",
    "                #print(input_train[-1][0][t])\n",
    "                input_train[-1][0][t] = tf.ragged.constant(input_train[-1][0][t])\n",
    "            input_train[-1][1]['target_label'] = tf.ragged.constant(input_train[-1][1]['target_label'])\n",
    "            input_train.append([{'input_nodes' : [], 'input_edges' : [], \n",
    "                     'incidence_matrix_sender' : [], 'incidence_matrix_receiver': []}, {'target_label' : []}])\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76c2d57-c367-4ed6-beae-ba6ce7d72d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"input_components = np.array(input_components)\\nprint(len(input_components[1][0]['input_nodes']),\\n     len(input_train[0][0]['input_edges']))\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"input_components = np.array(input_components)\n",
    "print(len(input_components[1][0]['input_nodes']),\n",
    "     len(input_train[0][0]['input_edges']))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac94192-d616-4fa8-9e1d-16f696be3346",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(input_components[1][1][\\'target_label\\'])\\nbatch_size=3\\nprint(batch_size)\\ninput_components = np.array(input_components)\\nstart_time = time.time()\\n#prep_inputs()\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\\nstart_time = time.time()\\nprep_inputs2()\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\\nprint(max([len(n.nodes) for n in g.batches]))\\nprint(input_train[0][0][\\'input_nodes\\'][0].shape)\\nprint(input_components[1][0][\\'input_nodes\\'][0].shape)\\nprint(max([len(i[0][\\'input_nodes\\'][0]) for i in input_components]))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(input_components[1][1]['target_label'])\n",
    "batch_size=3\n",
    "print(batch_size)\n",
    "input_components = np.array(input_components)\n",
    "start_time = time.time()\n",
    "#prep_inputs()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "prep_inputs2()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(max([len(n.nodes) for n in g.batches]))\n",
    "print(input_train[0][0]['input_nodes'][0].shape)\n",
    "print(input_components[1][0]['input_nodes'][0].shape)\n",
    "print(max([len(i[0]['input_nodes'][0]) for i in input_components]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a41a7d7-aa5a-4698-8de4-f1cfcbc921fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, val, epoch_len):\n",
    "        self.val = val\n",
    "        self.epoch_len = epoch_len\n",
    "        self.shuffle=True\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.epoch_len #number of gradient descent steps per epoch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        global input_train\n",
    "        'Updates indexes after each epoch'\n",
    "        #prep_inputs3()\n",
    "        #self.epoch_len = len(input_train)-1\n",
    "        #self.indexes = np.arange(self.epoch_len)\n",
    "        #input_train = []\n",
    "        #for g in graph_list:            \n",
    "            #i, _, _, _, _ = get_batches(g, int(numb_batches_train / len(train_species)), \n",
    "                                        #batch_size, int(numb_batches_train_no_edge / len(train_species)),0)\n",
    "            #input_train += i\n",
    "        #if self.shuffle == True:\n",
    "            #np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __getitem__(self, _index):\n",
    "        #i = self.indexes[_index]\n",
    "        if self.val:\n",
    "            return input_val[_index][0], input_val[_index][1]\n",
    "        else:\n",
    "            return input_train[_index][0], input_train[_index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e60d04e-c521-4191-a43e-0bffe112d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_species = ['Populus_trichocarpa','Drosophila_melanogaster', \n",
    "                    'Medicago_truncatula', 'Caenorhabditis_elegans']\n",
    "#train_species = ['Caenorhabditis_elegans', 'Drosophila_melanogaster', \n",
    "                 #'Medicago_truncatula']\n",
    "#train_species= ['Drosophila_melanogaster']\n",
    "val_species = ['Arabidopsis_thaliana', 'Danio_rerio'\n",
    "               ]\n",
    "#val_species= ['Drosophila_melanogaster']\n",
    "\n",
    "quiet = True\n",
    "numb_batches_train = 150 * len(train_species)\n",
    "numb_batches_val = 120 *len(val_species)\n",
    "numb_batches_train_no_edge = 75 * len(train_species)\n",
    "numb_batches_val_no_edge = 75 *len(val_species)\n",
    "numb_nodes_per_species = 17000\n",
    "batch_size = 256#128\n",
    "v=0\n",
    "brain_dir = '/home/jovyan/brain/'\n",
    "parent_dir = '/home/jovyan/Proj/ml_combiner/data/train_data'\n",
    "out = f'{parent_dir}/train2/train4'\n",
    "weight_class_one = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ad0e55-589d-4162-968d-58e03267c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_max():\n",
    "    e_f1 = []\n",
    "    e_f2 = []\n",
    "    for g in graph_list:        \n",
    "        for edge in g.edges.values():            \n",
    "            e_f1.append(edge.feature_vector_n1_to_n2)\n",
    "            e_f2.append(edge.feature_vector_n2_to_n1)           \n",
    "            \n",
    "    e_f1 = np.array(e_f1)[:,:120]\n",
    "    e_f2 = np.array(e_f2)[:,:120]\n",
    "    print(e_f1.shape)\n",
    "    print(e_f2.shape)\n",
    "    print('EDGES ni to nj')\n",
    "    print('MEAN\\n', [i for i in np.mean(e_f1, axis=0)])\n",
    "    print('STD\\n',[i for i in np.std(e_f1, axis=0)])\n",
    "    print('MAX\\n',[i for i in np.max(e_f1, axis=0)])\n",
    "    print('MIN\\n',[i for i in np.min(e_f1, axis=0)])\n",
    "    print('\\nEDGES nj to ni')\n",
    "    print('MEAN\\n', [i for i in np.mean(e_f2, axis=0)])\n",
    "    print('STD\\n',[i for i in np.std(e_f2, axis=0)])\n",
    "    print('MAX\\n',[i for i in np.max(e_f2, axis=0)])\n",
    "    print('MIN\\n',[i for i in np.min(e_f2, axis=0)])\n",
    "    \n",
    "def get_node_max():\n",
    "    n_f = []\n",
    "    for g in graph_list:        \n",
    "        for node in g.nodes.values():            \n",
    "            n_f.append(node.feature_vector)     \n",
    "            \n",
    "    n_f = np.array(n_f)[:,:80]\n",
    "    print(n_f.shape)\n",
    "    print('NODES')\n",
    "    print('MEAN\\n', [i for i in np.mean(n_f, axis=0)])\n",
    "    print('STD\\n',[i for i in np.std(n_f, axis=0)])\n",
    "    print('MAX\\n',[i for i in np.max(n_f, axis=0)])\n",
    "    print('MIN\\n',[i for i in np.min(n_f, axis=0)])\n",
    "    print('MIN\\n',[i for i in np.min(n_f, axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e1c3b2-ccb8-466c-b470-db5011670007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe_features(graph):\n",
    "    n_f = []    \n",
    "    n_f_true = []\n",
    "    e_f_tt = []\n",
    "    e_f_tf = []\n",
    "    e_f_ft = []\n",
    "    e_f_ff = []\n",
    "    \n",
    "#     for node in graph.nodes.values():\n",
    "#         n_f.append(node.feature_vector)\n",
    "#     for edge in graph.edges.values():\n",
    "#         e_f.append(edge.feature_vector_n1_to_n2)\n",
    "#         e_f.append(edge.feature_vector_n2_to_n1)\n",
    "    for g in graph_list:\n",
    "        for node in g.nodes.values():\n",
    "            if node.is_in_ref_anno:\n",
    "                n_f_true.append(node.feature_vector)\n",
    "            else:\n",
    "                n_f.append(node.feature_vector)\n",
    "        for edge in g.edges.values():\n",
    "            n1 = g.nodes[edge.node1]\n",
    "            n2 = g.nodes[edge.node2]\n",
    "            if n1.is_in_ref_anno and n2.is_in_ref_anno:                \n",
    "                e_f_tt.append(edge.feature_vector_n1_to_n2)\n",
    "                e_f_tt.append(edge.feature_vector_n2_to_n1)\n",
    "            elif n1.is_in_ref_anno and not n2.is_in_ref_anno:\n",
    "                e_f_tf.append(edge.feature_vector_n1_to_n2)\n",
    "                e_f_ft.append(edge.feature_vector_n2_to_n1)\n",
    "            elif not n1.is_in_ref_anno and n2.is_in_ref_anno:\n",
    "                e_f_ft.append(edge.feature_vector_n1_to_n2)\n",
    "                e_f_tf.append(edge.feature_vector_n2_to_n1)\n",
    "            elif not n1.is_in_ref_anno and not n2.is_in_ref_anno:\n",
    "                e_f_ff.append(edge.feature_vector_n1_to_n2)\n",
    "                e_f_ff.append(edge.feature_vector_n2_to_n1)\n",
    "            \n",
    "    n_f = np.array(n_f)\n",
    "    n_f_true = np.array(n_f_true)\n",
    "    print(n_f.shape)\n",
    "    print(n_f_true.shape)\n",
    "    e_f_ff = np.array(e_f_ff)\n",
    "    e_f_tt = np.array(e_f_tt)\n",
    "    e_f_tf = np.array(e_f_tf)\n",
    "    e_f_ft = np.array(e_f_ft)\n",
    "    print(e_f_tt.shape)\n",
    "    print(e_f_ft.shape)\n",
    "    print(e_f_tf.shape)\n",
    "    print(e_f_ff.shape)\n",
    "    \n",
    "    n_f_all = np.concatenate((n_f,n_f_true))\n",
    "    print(n_f_all.shape)\n",
    "    e_f_all = np.concatenate((e_f_ff,e_f_tt,e_f_tf,e_f_ft))\n",
    "    print('NODES')\n",
    "    print('MEAN\\n', [i for i in np.mean(n_f_all, axis=0)])\n",
    "    print('STD\\n', [i for i in np.std(n_f_all, axis=0)])\n",
    "    print('MAX\\n', [i for i in np.max(n_f_all, axis=0)])\n",
    "    print('Min\\n', [i for i in np.min(n_f_all, axis=0)])\n",
    "    print('EDGES')\n",
    "    print('MEAN\\n', [i for i in np.mean(e_f_all, axis=0)])\n",
    "    print('STD\\n',[i for i in np.std(e_f_all, axis=0)])\n",
    "    print('MAX\\n',[i for i in np.max(e_f_all, axis=0)])\n",
    "    print('MIN\\n',[i for i in np.min(e_f_all, axis=0)])\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols = 1, nrows=4, figsize=(15,9))\n",
    "    i = int(n_f.shape[1] / 4 + 0.5)\n",
    "    for j in range(4):\n",
    "        data = [n_f[:,k] for k in range(i*j, min(i*(j+1), n_f.shape[1]))]\n",
    "        data2 = [n_f_true[:,k] for k in range(i*j, min(i*(j+1), n_f_true.shape[1]))]\n",
    "        bp = ax[j].boxplot(data, positions=np.array(range(len(data)))*2.0-0.4, sym='', widths=0.6)\n",
    "        for item in ['boxes', 'medians']:            \n",
    "            plt.setp(bp[item], color='red')\n",
    "        bp = ax[j].boxplot(data2, positions=np.array(range(len(data2)))*2.0+0.4, sym='', widths=0.6)\n",
    "        for item in ['boxes', 'medians']:            \n",
    "            plt.setp(bp[item], color='green')\n",
    "        ax[j].set_ylim([-3,3])\n",
    "        ax[j].set_xticks([])\n",
    "        \n",
    "    plt.savefig(brain_dir + '/test_data/ml_training/plot/node_features.png', dpi=200)\n",
    "    fig.suptitle(f'node features')\n",
    "    fig, ax = plt.subplots(ncols = 1, nrows=4, figsize=(15,9))\n",
    "    i = int(e_f_tt.shape[1] / 4 + 0.5)\n",
    "    for j in range(4):\n",
    "        for c, e_f, v in zip(['red', 'orange', 'violet', 'green'], [e_f_ff, e_f_ft, e_f_tf, e_f_tt], \n",
    "                            [1.1, 0.4, -0.4, -1.1]):\n",
    "            data = [e_f[:,k] for k in range(i*j, min(i*(j+1), e_f.shape[1]))]\n",
    "            bp = ax[j].boxplot(data, positions=np.array(range(len(data)))*4.0-v, sym='', widths=0.6)\n",
    "            for item in ['boxes', 'medians']:            \n",
    "                plt.setp(bp[item], color=c)\n",
    "        ax[j].set_ylim([-3,3])\n",
    "    fig.suptitle(f'edge features')\n",
    "    plt.savefig(brain_dir + '/test_data/ml_training/plot/edge_features.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ab1cd7-fcd8-4646-8ede-bfe501c4281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def get_batches(tx_sets, evi, anno, numb_b, b_size, v_size, des=False):\n",
    "    graph = Graph(tx_sets, verbose=v)\n",
    "    graph.build()\n",
    "    graph.add_node_features(evi)\n",
    "    graph.add_edge_features(evi)\n",
    "    graph.add_reference_anno_label(anno)\n",
    "    graph.create_batch(numb_b, b_size, repl=False)    \n",
    "    train, val = graph.get_batches_as_input_target(v_size)\n",
    "    if des:\n",
    "        describe_features(graph)\n",
    "    return train, val, graph\"\"\"\n",
    "\n",
    "def get_batches(graph, numb_b, b_size, numb_b_n_e, v_size, des=False):    \n",
    "    graph.create_batch(numb_b, b_size, repl=False)  \n",
    "    #graph.create_batch_no_edges(numb_b_n_e, b_size, repl=False)\n",
    "    train, val, train_no_edge, val_no_edge = graph.get_batches_as_input_target(v_size)\n",
    "    if des:\n",
    "        describe_features(graph)\n",
    "    return train, val, train_no_edge, val_no_edge, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e45ef0-c2d5-46fc-94d5-367a49e29ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c = 1\\ngene_sets = []\\nval_sets = []\\nfor b in ['braker1', 'braker2']:        \\n    gene_sets.append(Anno(f'{parent_dir}/{b}_train.gtf', f'anno{c}'))\\n    gene_sets[-1].addGtf()\\n    gene_sets[-1].norm_tx_format()\\n    val_sets.append(Anno(f'{parent_dir}/{b}_val.gtf', f'anno{c}'))\\n    val_sets[-1].addGtf()\\n    val_sets[-1].norm_tx_format()\\n\\n    c += 1\\n\\nref_anno = Anno(f'{parent_dir}/annot_train.gtf', 'reference')\\nref_anno.addGtf()\\nref_anno.norm_tx_format()\\nref_anno_val = Anno(f'{parent_dir}/annot_val.gtf', 'reference')\\nref_anno_val.addGtf()\\nref_anno_val.norm_tx_format()\\n\\n# read hintfiles\\nevi_train = Evidence()\\nfor h in ['hints1', 'hints2']:    \\n    evi_train.add_hintfile(f'{parent_dir}/{h}_train.gff')\\n    \\nevi_val = Evidence()\\nfor h in ['hints1', 'hints2']:        \\n    evi_val.add_hintfile(f'{parent_dir}/{h}_val.gff')\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"c = 1\n",
    "gene_sets = []\n",
    "val_sets = []\n",
    "for b in ['braker1', 'braker2']:        \n",
    "    gene_sets.append(Anno(f'{parent_dir}/{b}_train.gtf', f'anno{c}'))\n",
    "    gene_sets[-1].addGtf()\n",
    "    gene_sets[-1].norm_tx_format()\n",
    "    val_sets.append(Anno(f'{parent_dir}/{b}_val.gtf', f'anno{c}'))\n",
    "    val_sets[-1].addGtf()\n",
    "    val_sets[-1].norm_tx_format()\n",
    "\n",
    "    c += 1\n",
    "\n",
    "ref_anno = Anno(f'{parent_dir}/annot_train.gtf', 'reference')\n",
    "ref_anno.addGtf()\n",
    "ref_anno.norm_tx_format()\n",
    "ref_anno_val = Anno(f'{parent_dir}/annot_val.gtf', 'reference')\n",
    "ref_anno_val.addGtf()\n",
    "ref_anno_val.norm_tx_format()\n",
    "\n",
    "# read hintfiles\n",
    "evi_train = Evidence()\n",
    "for h in ['hints1', 'hints2']:    \n",
    "    evi_train.add_hintfile(f'{parent_dir}/{h}_train.gff')\n",
    "    \n",
    "evi_val = Evidence()\n",
    "for h in ['hints1', 'hints2']:        \n",
    "    evi_val.add_hintfile(f'{parent_dir}/{h}_val.gff')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ef51f7-d7df-4891-859c-ecacd76e01ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n",
      "17002\n",
      "17001\n",
      "17000\n",
      "8500\n",
      "8503\n"
     ]
    }
   ],
   "source": [
    "#input_train, _, g1 = get_batches(gene_sets, evi_train, ref_anno, numb_batches_train, batch_size, 0)\n",
    "#input_val, _, g2 = get_batches(val_sets, evi_val, ref_anno_val, numb_batches_val, batch_size, 0) \n",
    "input_train = []\n",
    "input_components = []\n",
    "input_train_no_edge = []\n",
    "input_val = []\n",
    "input_val_no_edge = []\n",
    "graph_list = []\n",
    "train_components=[]\n",
    "val_components=[]\n",
    "for s in train_species:\n",
    "    #with open(f'{brain_dir}/test_data/ml_training/train_data/{s}_graph_object.pkl', 'rb') as inp:\n",
    "    with open(f'{brain_dir}/test_data/ml_training/train_data/{s}_altseqs_graph_object.pkl', 'rb') as inp:\n",
    "        g = pickle.load(inp)\n",
    "        graph_list.append(g)\n",
    "    #i, _, j, _, _ = get_batches(g, int(numb_batches_train / len(train_species)), \n",
    "                                #batch_size, int(numb_batches_train_no_edge / len(train_species)),0)\n",
    "    i, _ = g.get_components_as_input_target(numb_nodes_per_species, 0, True)    \n",
    "    train_components += i\n",
    "    #input_train_no_edge += j\n",
    "\n",
    "for s in val_species:\n",
    "    #with open(f'{brain_dir}/test_data/ml_training/train_data/{s}_graph_object.pkl', 'rb') as inp:\n",
    "    with open(f'{brain_dir}/test_data/ml_training/train_data/{s}_altseqs_graph_object.pkl', 'rb') as inp:\n",
    "        g = pickle.load(inp)\n",
    "    #i, _, j, _, _ = get_batches(g, int(numb_batches_val / len(val_species)), \n",
    "                                #batch_size, numb_batches_val_no_edge, 0)\n",
    "    \n",
    "    i, _ = g.get_components_as_input_target(int(numb_nodes_per_species/2), 1, True)\n",
    "    val_components += i\n",
    "    #input_val_no_edge += j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a138ef9c-dc0c-454c-8080-500d457e978f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#describe_features(graph_list[0])\n",
    "#get_node_max()\n",
    "#get_edge_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d635978f-87d9-4eee-9f46-fc0dc52e7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = get_inputs(train_components, batch_size, False)\n",
    "input_val = get_inputs(val_components, batch_size, False)\n",
    "train_gen = SampleGenerator(False, len(input_train))#int(numb_batches * (1-val_size)))\n",
    "val_gen = SampleGenerator(True, len(input_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b77453fd-0c18-4a78-ac80-3c7788e9515a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68266 17883.0 2.8173684504836998\n"
     ]
    }
   ],
   "source": [
    "set_weight()\n",
    "gnn = GNN(weight_class_one=weight_class_one)\n",
    "gnn.compile(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfc0a7-d396-44d4-af0b-c73a1c07a469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "263/263 [==============================] - 7s 18ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9798 - val_loss: 2.8727 - val_last_iteration_binary_accuracy: 0.9702\n",
      "Epoch 2/5000\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9668 - val_loss: 2.9402 - val_last_iteration_binary_accuracy: 0.9663\n",
      "Epoch 3/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9651 - val_loss: 2.8826 - val_last_iteration_binary_accuracy: 0.9650\n",
      "Epoch 4/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9645 - val_loss: 2.8928 - val_last_iteration_binary_accuracy: 0.9644\n",
      "Epoch 5/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2191 - last_iteration_binary_accuracy: 0.9639 - val_loss: 2.8834 - val_last_iteration_binary_accuracy: 0.9639\n",
      "Epoch 6/5000\n",
      "263/263 [==============================] - 5s 17ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.9735 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 7/5000\n",
      "263/263 [==============================] - 5s 17ms/step - loss: 0.2191 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9500 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 8/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0186 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 9/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9631 - val_loss: 3.0051 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 10/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9630 - val_loss: 3.0279 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 11/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2194 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8529 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 12/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9648 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 13/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9629 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 14/5000\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9521 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 15/5000\n",
      "263/263 [==============================] - 5s 19ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9773 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 16/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2300 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8850 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 17/5000\n",
      "263/263 [==============================] - 5s 19ms/step - loss: 0.2249 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8042 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 18/5000\n",
      "263/263 [==============================] - 5s 20ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.7673 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 19/5000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.8365 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 20/5000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8944 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 21/5000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9368 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 22/5000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9475 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 23/5000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9422 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 24/5000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9119 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 25/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9648 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 26/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9116 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 27/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9263 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 28/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9459 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 29/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9741 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 30/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9758 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 31/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9309 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 32/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2273 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.5432 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 33/5000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 0.2310 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.6202 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 34/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2226 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7239 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 35/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8158 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 36/5000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8869 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 37/5000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9081 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 38/5000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9173 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 39/5000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6975 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 40/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9000 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 41/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8324 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 42/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8573 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 43/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8925 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 44/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2184 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8075 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 45/5000\n",
      "263/263 [==============================] - 5s 17ms/step - loss: 0.2231 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6900 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 46/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2205 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7417 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 47/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7861 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 48/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8439 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 49/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8549 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 50/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8709 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 51/5000\n",
      "263/263 [==============================] - 5s 19ms/step - loss: 0.2190 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7964 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 52/5000\n",
      "263/263 [==============================] - 5s 20ms/step - loss: 0.2268 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9240 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 53/5000\n",
      "263/263 [==============================] - 5s 20ms/step - loss: 0.2235 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7004 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 54/5000\n",
      "263/263 [==============================] - 5s 19ms/step - loss: 0.2189 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7928 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 55/5000\n",
      "263/263 [==============================] - 5s 19ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8282 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 56/5000\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8787 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 57/5000\n",
      "263/263 [==============================] - 5s 20ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9393 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 58/5000\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8649 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 59/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8728 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 60/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9339 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 61/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9014 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 62/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9081 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 63/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2194 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9930 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 64/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2292 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8198 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 65/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2226 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.7086 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 66/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.8283 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 67/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.8573 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 68/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.9007 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 69/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.9389 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 70/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.9802 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 71/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9344 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 72/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2240 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.6836 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 73/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2241 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.7321 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 74/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.8789 - val_last_iteration_binary_accuracy: 0.9623\n",
      "Epoch 75/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.9667 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 76/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.9556 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 77/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9623 - val_loss: 2.9214 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 78/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9866 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 79/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9564 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 80/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9312 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 81/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9721 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 82/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9374 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 83/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2212 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8751 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 84/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2346 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7957 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 85/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2269 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7214 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 86/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8000 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 87/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2196 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6865 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 88/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8574 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 89/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8373 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 90/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8290 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 91/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8204 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 92/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8416 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 93/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8709 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 94/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8585 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 95/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9503 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 96/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2198 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8685 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 97/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2315 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6259 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 98/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2221 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7188 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 99/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7624 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 100/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8252 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 101/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8224 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 102/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8977 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 103/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7865 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 104/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7378 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 105/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7532 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 106/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8338 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 107/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8669 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 108/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7434 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 109/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8439 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 110/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8795 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 111/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9599 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 112/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9503 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 113/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8987 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 114/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9650 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 115/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9097 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 116/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2273 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7706 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 117/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2250 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8475 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 118/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2211 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8823 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 119/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9476 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 120/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9616 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 121/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2152 - last_iteration_binary_accuracy: 0.9624 - val_loss: 3.0661 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 122/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9624 - val_loss: 3.0435 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 123/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9624 - val_loss: 3.0194 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 124/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9933 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 125/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2213 - last_iteration_binary_accuracy: 0.9624 - val_loss: 3.0032 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 126/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2199 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9072 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 127/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9428 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 128/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9931 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 129/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9236 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 130/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9425 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 131/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2184 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8402 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 132/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9587 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 133/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9298 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 134/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2201 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9009 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 135/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2268 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7356 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 136/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2235 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7486 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 137/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7657 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 138/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8547 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 139/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7786 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 140/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8387 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 141/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8549 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 142/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8840 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 143/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8158 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 144/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9095 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 145/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8807 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 146/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9150 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 147/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2222 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7332 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 148/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2235 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7662 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 149/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2238 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7570 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 150/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2216 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8133 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 151/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2203 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8564 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 152/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8802 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 153/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9144 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 154/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8599 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 155/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8426 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 156/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8889 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 157/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8986 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 158/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9450 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 159/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8967 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 160/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2231 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8247 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 161/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2236 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8972 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 162/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2196 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7861 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 163/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8417 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 164/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6008 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 165/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2206 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7720 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 166/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7468 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 167/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8075 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 168/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8738 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 169/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8545 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 170/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8648 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 171/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2200 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9673 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 172/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2276 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8279 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 173/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2261 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6801 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 174/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2202 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7130 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 175/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7431 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 176/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7873 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 177/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7960 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 178/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8060 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 179/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8447 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 180/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8923 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 181/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7074 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 182/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2191 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7546 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 183/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7577 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 184/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2266 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7674 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 185/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2273 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6296 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 186/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2214 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.6766 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 187/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7308 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 188/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7839 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 189/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7911 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 190/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8162 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 191/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8137 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 192/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7793 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 193/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2191 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7708 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 194/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8086 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 195/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8406 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 196/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8375 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 197/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8550 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 198/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8152 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 199/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8796 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 200/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9182 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 201/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2197 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.9246 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 202/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2192 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8062 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 203/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8629 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 204/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8083 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 205/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7857 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 206/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8307 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 207/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8283 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 208/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8916 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 209/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8923 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 210/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.7410 - val_last_iteration_binary_accuracy: 0.9624\n",
      "Epoch 211/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2260 - last_iteration_binary_accuracy: 0.9624 - val_loss: 2.8037 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 212/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2250 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.7358 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 213/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.7937 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 214/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.8000 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 215/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9198 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 216/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.6969 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 217/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2214 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.7194 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 218/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2221 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9151 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 219/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.8416 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 220/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.8953 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 221/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.8853 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 222/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9053 - val_last_iteration_binary_accuracy: 0.9625\n",
      "Epoch 223/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9625 - val_loss: 2.9206 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 224/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8729 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 225/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8462 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 226/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8500 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 227/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9025 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 228/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8586 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 229/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8716 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 230/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2204 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8995 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 231/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2321 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8852 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 232/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2210 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.8997 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 233/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9817 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 234/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9626 - val_loss: 2.9932 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 235/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9626 - val_loss: 3.0144 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 236/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9626 - val_loss: 3.0616 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 237/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9626 - val_loss: 3.0600 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 238/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9626 - val_loss: 3.0701 - val_last_iteration_binary_accuracy: 0.9626\n",
      "Epoch 239/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9626 - val_loss: 3.0555 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 240/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9626 - val_loss: 3.0440 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 241/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9627 - val_loss: 3.0434 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 242/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9407 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 243/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2243 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.7706 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 244/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2293 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.6785 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 245/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2214 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.7500 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 246/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8292 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 247/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9720 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 248/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9583 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 249/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9718 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 250/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8652 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 251/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8438 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 252/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8890 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 253/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9086 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 254/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8860 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 255/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8931 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 256/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8669 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 257/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9661 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 258/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.9201 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 259/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9627 - val_loss: 3.0798 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 260/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9627 - val_loss: 2.8475 - val_last_iteration_binary_accuracy: 0.9627\n",
      "Epoch 261/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9454 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 262/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9628 - val_loss: 3.0061 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 263/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9347 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 264/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9978 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 265/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.8591 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 266/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2192 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9681 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 267/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2237 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.7806 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 268/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2298 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.8790 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 269/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2221 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.8336 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 270/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.8551 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 271/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9169 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 272/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2152 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9757 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 273/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9349 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 274/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9629 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 275/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9786 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 276/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9628 - val_loss: 3.0008 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 277/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9489 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 278/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2203 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.9422 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 279/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2307 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.7645 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 280/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2204 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.7778 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 281/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.8670 - val_last_iteration_binary_accuracy: 0.9628\n",
      "Epoch 282/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9628 - val_loss: 2.8883 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 283/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9731 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 284/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9295 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 285/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9333 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 286/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9170 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 287/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9139 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 288/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8446 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 289/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2206 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9157 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 290/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2237 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.7895 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 291/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2251 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8250 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 292/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2206 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9135 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 293/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9577 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 294/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9741 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 295/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9812 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 296/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9629 - val_loss: 3.0321 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 297/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9182 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 298/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9429 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 299/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9505 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 300/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9563 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 301/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9638 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 302/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8975 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 303/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8945 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 304/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9364 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 305/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9715 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 306/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9629 - val_loss: 3.0566 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 307/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9448 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 308/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8431 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 309/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2306 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.7394 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 310/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2286 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8816 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 311/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2200 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.7938 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 312/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2205 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.8935 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 313/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9004 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 314/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9629 - val_loss: 2.9010 - val_last_iteration_binary_accuracy: 0.9629\n",
      "Epoch 315/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9487 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 316/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9672 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 317/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9632 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 318/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2197 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9772 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 319/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9330 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 320/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9000 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 321/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9784 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 322/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9677 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 323/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9630 - val_loss: 3.0471 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 324/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9348 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 325/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2200 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.7635 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 326/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2251 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9742 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 327/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2219 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8478 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 328/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2202 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8796 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 329/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9294 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 330/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9108 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 331/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9436 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 332/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9728 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 333/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9757 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 334/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9028 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 335/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9117 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 336/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9450 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 337/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9771 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 338/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9305 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 339/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9598 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 340/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2202 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.7008 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 341/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2362 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.7356 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 342/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2234 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.7386 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 343/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2184 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.7960 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 344/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8783 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 345/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8598 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 346/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8836 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 347/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9083 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 348/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8443 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 349/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9275 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 350/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.9946 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 351/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8996 - val_last_iteration_binary_accuracy: 0.9630\n",
      "Epoch 352/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9630 - val_loss: 2.8452 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 353/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9336 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 354/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2192 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8408 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 355/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2273 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8237 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 356/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2324 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.6398 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 357/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2196 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7873 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 358/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8124 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 359/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8711 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 360/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9287 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 361/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2149 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9556 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 362/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2148 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9795 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 363/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9975 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 364/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9846 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 365/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2206 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9342 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 366/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2205 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8947 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 367/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8334 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 368/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9507 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 369/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8664 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 370/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9539 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 371/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9395 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 372/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7644 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 373/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8560 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 374/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9185 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 375/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9542 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 376/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2191 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7391 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 377/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2263 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7230 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 378/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2260 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7684 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 379/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2210 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8249 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 380/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7620 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 381/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7783 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 382/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8678 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 383/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9277 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 384/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9144 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 385/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9354 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 386/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9121 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 387/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.7568 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 388/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9095 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 389/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8317 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 390/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8676 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 391/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2189 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.9187 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 392/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9631 - val_loss: 2.8769 - val_last_iteration_binary_accuracy: 0.9631\n",
      "Epoch 393/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2195 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.9146 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 394/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2247 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8297 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 395/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2230 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8967 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 396/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2207 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8162 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 397/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8434 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 398/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8996 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 399/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.9163 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 400/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8963 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 401/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8231 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 402/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8833 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 403/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8397 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 404/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8505 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 405/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.9232 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 406/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8756 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 407/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8768 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 408/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2197 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8776 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 409/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2277 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.6869 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 410/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2291 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.5584 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 411/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2192 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.7480 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 412/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8337 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 413/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8341 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 414/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8437 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 415/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8704 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 416/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.7862 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 417/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8293 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 418/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8964 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 419/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8354 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 420/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8396 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 421/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8321 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 422/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8546 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 423/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8149 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 424/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.7958 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 425/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8546 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 426/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.9227 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 427/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8574 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 428/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2251 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8284 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 429/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2293 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.8115 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 430/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2252 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.7409 - val_last_iteration_binary_accuracy: 0.9632\n",
      "Epoch 431/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9632 - val_loss: 2.7996 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 432/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9119 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 433/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9366 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 434/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9497 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 435/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9356 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 436/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8141 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 437/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9708 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 438/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0473 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 439/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9369 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 440/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9162 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 441/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8976 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 442/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8804 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 443/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2210 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8092 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 444/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2216 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9256 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 445/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.7811 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 446/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8410 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 447/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8233 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 448/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8432 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 449/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8320 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 450/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8260 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 451/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8847 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 452/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9631 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 453/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9509 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 454/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9770 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 455/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8707 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 456/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2301 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.7692 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 457/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2233 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8333 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 458/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8451 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 459/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8665 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 460/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9250 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 461/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9505 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 462/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9919 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 463/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9953 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 464/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9468 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 465/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9956 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 466/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9067 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 467/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9434 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 468/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9942 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 469/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9243 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 470/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2239 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8197 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 471/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2332 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8784 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 472/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2208 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9473 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 473/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9230 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 474/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9489 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 475/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9688 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 476/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0155 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 477/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0524 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 478/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9527 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 479/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9597 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 480/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9810 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 481/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0563 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 482/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2212 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8570 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 483/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2249 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8416 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 484/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2198 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8873 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 485/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0186 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 486/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9030 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 487/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0133 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 488/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9615 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 489/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0513 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 490/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9547 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 491/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9647 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 492/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9964 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 493/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2192 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8457 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 494/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2251 - last_iteration_binary_accuracy: 0.9633 - val_loss: 3.0179 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 495/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8896 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 496/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.9283 - val_last_iteration_binary_accuracy: 0.9633\n",
      "Epoch 497/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9633 - val_loss: 2.8742 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 498/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9397 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 499/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8633 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 500/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2184 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8944 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 501/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2196 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9234 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 502/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2215 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.7581 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 503/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2314 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8129 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 504/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2189 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.7804 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 505/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8475 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 506/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9201 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 507/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2150 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9601 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 508/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9794 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 509/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9291 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 510/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9135 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 511/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9367 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 512/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9179 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 513/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8561 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 514/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9040 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 515/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8663 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 516/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9708 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 517/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9657 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 518/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2213 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0342 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 519/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2272 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.6385 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 520/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2195 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8446 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 521/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9105 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 522/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9750 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 523/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9986 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 524/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9615 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 525/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0049 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 526/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0111 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 527/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0237 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 528/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0281 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 529/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0199 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 530/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0202 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 531/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.1159 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 532/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2258 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.6846 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 533/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2256 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8449 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 534/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9179 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 535/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9233 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 536/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0302 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 537/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2152 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0614 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 538/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0134 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 539/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0303 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 540/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9803 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 541/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9441 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 542/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2195 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0294 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 543/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2192 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8687 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 544/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2203 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9276 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 545/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2192 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8735 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 546/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9910 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 547/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0140 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 548/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0693 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 549/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0095 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 550/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9837 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 551/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9796 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 552/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9531 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 553/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2215 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9158 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 554/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2259 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.6879 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 555/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2213 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8368 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 556/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8033 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 557/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8726 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 558/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9031 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 559/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8963 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 560/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8996 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 561/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9291 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 562/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8949 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 563/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9490 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 564/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8768 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 565/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9165 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 566/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9307 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 567/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2211 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8454 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 568/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9724 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 569/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8780 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 570/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0333 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 571/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9555 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 572/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9634 - val_loss: 3.0527 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 573/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2211 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8777 - val_last_iteration_binary_accuracy: 0.9634\n",
      "Epoch 574/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2308 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9019 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 575/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2220 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.9087 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 576/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9634 - val_loss: 2.8671 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 577/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9584 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 578/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9633 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 579/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2150 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0099 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 580/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0026 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 581/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9447 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 582/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9635 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 583/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8863 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 584/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9607 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 585/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9770 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 586/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9510 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 587/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9799 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 588/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9490 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 589/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9357 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 590/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2215 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8213 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 591/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2241 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7921 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 592/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2254 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7886 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 593/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2205 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9231 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 594/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9890 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 595/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9333 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 596/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9534 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 597/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9559 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 598/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9718 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 599/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9554 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 600/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9109 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 601/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0239 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 602/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9437 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 603/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9546 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 604/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0538 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 605/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9614 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 606/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9323 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 607/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2271 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.6713 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 608/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2236 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8607 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 609/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7905 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 610/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9098 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 611/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2199 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8895 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 612/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2206 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9501 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 613/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0346 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 614/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9919 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 615/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2150 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0801 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 616/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2149 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0608 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 617/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9985 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 618/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9833 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 619/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0659 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 620/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0342 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 621/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0621 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 622/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0633 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 623/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9610 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 624/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2207 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0415 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 625/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2246 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8134 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 626/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2196 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0028 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 627/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.1144 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 628/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0973 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 629/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.1209 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 630/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.1480 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 631/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0331 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 632/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9178 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 633/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2184 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.1510 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 634/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2288 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7950 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 635/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2226 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8267 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 636/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8465 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 637/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9284 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 638/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9694 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 639/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2152 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9555 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 640/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0085 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 641/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9213 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 642/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8104 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 643/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0229 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 644/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9774 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 645/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2190 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8992 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 646/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9281 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 647/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2195 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8764 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 648/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2234 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7636 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 649/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2203 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0312 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 650/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9954 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 651/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9843 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 652/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0101 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 653/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0563 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 654/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0766 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 655/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0228 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 656/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9784 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 657/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0411 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 658/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9045 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 659/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0508 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 660/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2211 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9753 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 661/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2237 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9697 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 662/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2198 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9145 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 663/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2190 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9915 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 664/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9482 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 665/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2200 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8390 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 666/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2212 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7237 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 667/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8137 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 668/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9038 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 669/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8917 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 670/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9634 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 671/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9145 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 672/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8972 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 673/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9341 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 674/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0110 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 675/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8956 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 676/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9445 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 677/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9877 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 678/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9152 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 679/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8391 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 680/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2205 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7969 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 681/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2273 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.6742 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 682/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2197 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7123 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 683/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8905 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 684/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9921 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 685/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9006 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 686/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9717 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 687/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9383 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 688/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9901 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 689/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9158 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 690/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9388 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 691/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7817 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 692/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8515 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 693/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9629 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 694/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9226 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 695/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2195 - last_iteration_binary_accuracy: 0.9635 - val_loss: 3.0398 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 696/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8644 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 697/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.7593 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 698/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9131 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 699/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9881 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 700/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9315 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 701/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2201 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8159 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 702/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2226 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9170 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 703/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2216 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.8759 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 704/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9065 - val_last_iteration_binary_accuracy: 0.9635\n",
      "Epoch 705/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9635 - val_loss: 2.9580 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 706/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9358 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 707/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9828 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 708/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9655 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 709/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9715 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 710/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9367 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 711/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9264 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 712/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8783 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 713/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2208 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8126 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 714/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2242 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9897 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 715/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2244 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7134 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 716/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2256 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7110 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 717/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8377 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 718/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8609 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 719/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8792 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 720/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2151 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9184 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 721/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2149 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9531 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 722/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9332 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 723/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9330 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 724/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8319 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 725/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2181 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9162 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 726/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8922 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 727/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9352 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 728/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9523 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 729/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9260 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 730/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2194 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8804 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 731/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2191 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.5947 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 732/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2195 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8275 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 733/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8198 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 734/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8344 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 735/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9167 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 736/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9221 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 737/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8915 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 738/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2259 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7413 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 739/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2226 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8794 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 740/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.6665 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 741/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9350 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 742/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9579 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 743/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9090 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 744/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9511 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 745/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9354 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 746/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9587 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 747/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9742 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 748/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9459 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 749/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9620 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 750/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0484 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 751/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0219 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 752/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0098 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 753/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0336 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 754/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2255 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8117 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 755/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2322 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.6236 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 756/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2183 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7343 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 757/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8801 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 758/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9019 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 759/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8966 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 760/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9090 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 761/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8734 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 762/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9305 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 763/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9765 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 764/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9936 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 765/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9152 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 766/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9938 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 767/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9743 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 768/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2187 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8888 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 769/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2307 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9510 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 770/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2202 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8670 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 771/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9311 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 772/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0297 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 773/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9951 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 774/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2173 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9447 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 775/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9973 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 776/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0368 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 777/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0421 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 778/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9855 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 779/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0119 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 780/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0729 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 781/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9723 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 782/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0492 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 783/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2201 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.6904 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 784/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2306 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8014 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 785/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2197 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7701 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 786/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8841 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 787/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9268 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 788/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9211 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 789/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9158 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 790/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9073 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 791/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2184 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7749 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 792/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2209 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8587 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 793/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2200 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8359 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 794/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2253 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.6928 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 795/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2229 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8111 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 796/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7800 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 797/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9063 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 798/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9507 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 799/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9929 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 800/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9549 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 801/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9182 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 802/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2203 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8695 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 803/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2198 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9509 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 804/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2194 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0086 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 805/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2188 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8918 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 806/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8766 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 807/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2208 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8276 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 808/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2204 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9023 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 809/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7690 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 810/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2237 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8340 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 811/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2210 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8877 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 812/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2222 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9137 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 813/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7711 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 814/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8758 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 815/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9193 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 816/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8689 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 817/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9002 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 818/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8938 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 819/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8454 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 820/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8389 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 821/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2196 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9376 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 822/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2186 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8222 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 823/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2190 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9736 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 824/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9612 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 825/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0062 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 826/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9604 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 827/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9989 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 828/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9930 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 829/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9965 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 830/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9721 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 831/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9734 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 832/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2311 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.5830 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 833/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2321 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8967 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 834/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2226 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7972 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 835/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8448 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 836/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9135 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 837/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2150 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9623 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 838/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2147 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9664 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 839/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2147 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0000 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 840/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2152 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9898 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 841/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9348 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 842/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8481 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 843/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2184 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9617 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 844/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2185 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0047 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 845/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9632 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 846/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8645 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 847/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8519 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 848/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9012 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 849/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9947 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 850/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2221 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8084 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 851/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2201 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8523 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 852/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8197 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 853/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9234 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 854/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9133 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 855/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9971 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 856/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2180 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9393 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 857/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8969 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 858/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9461 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 859/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9678 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 860/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9207 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 861/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9952 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 862/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9960 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 863/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2172 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8080 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 864/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2234 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8649 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 865/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2264 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8815 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 866/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2197 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0015 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 867/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0415 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 868/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0898 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 869/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0429 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 870/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9955 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 871/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0117 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 872/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9643 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 873/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2191 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0495 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 874/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2213 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9385 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 875/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2209 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7970 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 876/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2193 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9649 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 877/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2174 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8124 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 878/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9042 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 879/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9766 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 880/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9737 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 881/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2157 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9390 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 882/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9777 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 883/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9745 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 884/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9406 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 885/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9462 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 886/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9341 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 887/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8778 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 888/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8718 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 889/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2206 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9343 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 890/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2322 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7702 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 891/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2219 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7226 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 892/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7950 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 893/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8669 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 894/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8613 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 895/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9023 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 896/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9638 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 897/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2153 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9401 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 898/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2155 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9332 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 899/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9457 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 900/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2166 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9437 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 901/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9429 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 902/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0200 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 903/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2176 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8877 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 904/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2198 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8618 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 905/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2222 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9012 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 906/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2212 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7979 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 907/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8786 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 908/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9340 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 909/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9261 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 910/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2169 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9129 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 911/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9507 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 912/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9758 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 913/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9757 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 914/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2165 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9371 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 915/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9811 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 916/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9024 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 917/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2196 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9630 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 918/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2206 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9070 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 919/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2238 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8412 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 920/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2260 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9649 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 921/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2178 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9528 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 922/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9276 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 923/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2151 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0077 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 924/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2156 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0272 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 925/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2162 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9598 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 926/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2159 - last_iteration_binary_accuracy: 0.9636 - val_loss: 3.0128 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 927/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2158 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9959 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 928/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2179 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.8830 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 929/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2201 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.9110 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 930/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2262 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.6124 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 931/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2222 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.6981 - val_last_iteration_binary_accuracy: 0.9636\n",
      "Epoch 932/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2182 - last_iteration_binary_accuracy: 0.9636 - val_loss: 2.7216 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 933/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2175 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.7266 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 934/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.7773 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 935/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2148 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.8238 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 936/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2154 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.8393 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 937/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2163 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.7647 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 938/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2167 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.9040 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 939/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.8960 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 940/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2164 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.8698 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 941/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.9167 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 942/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2177 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.8915 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 943/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2170 - last_iteration_binary_accuracy: 0.9637 - val_loss: 3.0103 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 944/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2160 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.8809 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 945/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2161 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.9088 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 946/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2168 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.8855 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 947/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2171 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.7566 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 948/5000\n",
      "263/263 [==============================] - 3s 12ms/step - loss: 0.2210 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.9224 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 949/5000\n",
      "263/263 [==============================] - 3s 13ms/step - loss: 0.2285 - last_iteration_binary_accuracy: 0.9637 - val_loss: 2.7612 - val_last_iteration_binary_accuracy: 0.9637\n",
      "Epoch 950/5000\n",
      "132/263 [==============>...............] - ETA: 1s - loss: 0.2129 - last_iteration_binary_accuracy: 0.9637"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5000\n",
    "#history = gnn.train(train_gen, val_gen, NUM_EPOCHS, out) #!\n",
    "history = gnn.train(train_gen, val_gen, NUM_EPOCHS, out)\n",
    "\n",
    "history.history[\"last_iteration_binary_accuracy\"][-1]\n",
    "_, ax = plt.subplots(ncols = 2, figsize=(15,9))\n",
    "\n",
    "ax[0].plot(np.arange(NUM_EPOCHS), history.history[\"loss\"], 'b', label = 'Training loss')\n",
    "ax[0].plot(np.arange(NUM_EPOCHS), history.history[\"val_loss\"], 'g', label = 'Validation loss')\n",
    "ax[0].set_title('Training and validation loss')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_ylabel('loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(NUM_EPOCHS), history.history[\"last_iteration_binary_accuracy\"], 'b', label = 'Training accuracy')\n",
    "ax[1].plot(np.arange(NUM_EPOCHS), history.history[\"val_last_iteration_binary_accuracy\"], 'g', label = 'Validation accuracy')\n",
    "ax[1].set_title('Training and validation accuracy of the last message passing iteration')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(out + '.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a9cb6-c940-4599-aae0-eb9cd81ab350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gnn.predict(input_train[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e1a52-a66f-4a4b-b70d-a026b325d38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"input_train = input_train_no_edge\n",
    "input_val = input_val_no_edge\n",
    "train_gen = SampleGenerator(False, len(input_train))#int(numb_batches * (1-val_size)))\n",
    "val_gen = SampleGenerator(True, len(input_val))#int(numb_batches * val_size))\n",
    "\n",
    "NUM_EPOCHS = 500\n",
    "history = gnn.train_nn(train_gen, val_gen, NUM_EPOCHS, out) #!\n",
    "    \n",
    "history.history[\"last_iteration_binary_accuracy\"][-1]\n",
    "_, ax = plt.subplots(ncols = 2, figsize=(15,9))\n",
    "\n",
    "ax[0].plot(np.arange(NUM_EPOCHS), history.history[\"loss\"], 'b', label = 'Training loss')\n",
    "ax[0].plot(np.arange(NUM_EPOCHS), history.history[\"val_loss\"], 'g', label = 'Validation loss')\n",
    "ax[0].set_title('Training and validation loss')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_ylabel('loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(NUM_EPOCHS), history.history[\"last_iteration_binary_accuracy\"], 'b', label = 'Training accuracy')\n",
    "ax[1].plot(np.arange(NUM_EPOCHS), history.history[\"val_last_iteration_binary_accuracy\"], 'g', label = 'Validation accuracy')\n",
    "ax[1].set_title('Training and validation accuracy of the last message passing iteration')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(out + '.png', dpi=200)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
